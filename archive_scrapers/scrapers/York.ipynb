{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def get_subpages(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    current_year = datetime.now().year  # Get the current year dynamically\n",
    "    \n",
    "    subpages = set()\n",
    "    for year in range(current_year, 2009, -1):\n",
    "        for month in range(12, 0, -1):\n",
    "            if (year == current_year and month > datetime.datetime.now().month) or (year == 2010 and month < 9) or year > current_year or year < 2010:\n",
    "                continue  # Skip this year-month combination\n",
    "            subpage_url = f\"{url}{str(year)}/{month:02d}/\".replace(\"archives/\", \"\")\n",
    "            subpages.add(subpage_url)\n",
    "\n",
    "    return subpages, soup\n",
    "      # Return the set of subpages\n",
    "\n",
    "def get_article_links_and_dates(subpages):\n",
    "    articles = {}\n",
    "    links_set = set()\n",
    "    for subpage in subpages:\n",
    "        response = requests.get(subpage)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        articles_html = soup.find_all('article')\n",
    "        for article_html in articles_html:\n",
    "            link = article_html.find('a')['href']\n",
    "            if link not in links_set:\n",
    "                links_set.add(link)\n",
    "                date_str = re.findall(r'/(\\d{4})/(\\d{2})/(\\d{2})/', link)[0]\n",
    "                date = \"_\".join(date_str)\n",
    "                if date_str:\n",
    "                    if date not in articles:\n",
    "                        articles[date] = []\n",
    "                    articles[date].append(link)\n",
    "\n",
    "    return dict(sorted(articles.items(), key=lambda x: x[0], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "sub_pages = get_subpages(\"https://www.excal.on.ca/archives/\")\n",
    "\n",
    "# Call the function to get the scraped data\n",
    "scraped_data = get_article_links_and_dates(sub_pages)\n",
    "\n",
    "# Open a new file for writing and save the scraped data to it\n",
    "with open('york_article_pages.json', 'w') as outfile:\n",
    "        json.dump(scraped_data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.txt_to_text import get_article_text\n",
    "from helpers.make_txt_entry import make_txt_entry\n",
    "import os\n",
    "\n",
    "school_name = \"York\"\n",
    "dates = sorted(scraped_data.keys())\n",
    "\n",
    "for date in reversed(dates):\n",
    "    articles = scraped_data[date]\n",
    "    file_path = \"journal_data/txt/\"+school_name.replace(\" \",\"_\")+\"/\"+date+\".txt\"\n",
    "    if(os.path.exists(file_path)):\n",
    "        print(f\"Date {date} already added.\")\n",
    "    else:\n",
    "        article_text = \"\"\n",
    "        for article in articles:\n",
    "            article_text += get_article_text(article) + \"\\n\"\n",
    "            \n",
    "        make_txt_entry(school_name=\"York\", publication_date=date, text=article_text)\n",
    "        print(f\"Date {date} added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.graphers import monthly_grapher\n",
    "from helpers.queries import hillel_counter\n",
    "\n",
    "school_name = \"York\"\n",
    "newspaper_name = \"Excalibur\"\n",
    "school_name_lower = school_name.lower()\n",
    "\n",
    "York_pipeline = []\n",
    "\n",
    "directory = 'journal_data/txt/' + school_name\n",
    "\n",
    "monthly_grapher(directory=directory,\n",
    "                pipeline=York_pipeline,\n",
    "                query=hillel_counter,\n",
    "                y_label=\"Hillel Mentions Per Month\",\n",
    "                title=\"Mentions of Hillel in \" + newspaper_name,\n",
    "                save_path='figures/' + school_name + '/' + school_name + '_hillel_mentions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
