{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dana/Desktop/Olami\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change school, supported schools are: McGill, Georgetown, York, CMU, USC, AU, LIU\n",
    "SCHOOL = \"USF\"\n",
    "keywords = [\"conservative\", \"liberal\", \"Democrat\", \"Republican\", \"club\"]\n",
    "data_path = f\"journal_data/txt/{SCHOOL}\"\n",
    "output_path = f\"bias_processing/data/1/{SCHOOL.lower()}_dataset.poli.csv\"\n",
    "grouped_data_path = \"grouped_data/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date school       keyword  \\\n",
      "0      2009-01-04    USF  conservative   \n",
      "1      2009-01-05    USF  conservative   \n",
      "2      2009-01-06    USF  conservative   \n",
      "3      2009-01-07    USF  conservative   \n",
      "4      2009-01-08    USF  conservative   \n",
      "...           ...    ...           ...   \n",
      "13335  2023-05-31    USF          club   \n",
      "13336  2023-06-01    USF          club   \n",
      "13337  2023-06-02    USF          club   \n",
      "13338  2023-06-06    USF          club   \n",
      "13339  2023-06-08    USF          club   \n",
      "\n",
      "                                                 article  \n",
      "0      As coach Jim Leavitt stood on the pier in St. ...  \n",
      "1      YouTube is no longer just for water-skiing squ...  \n",
      "2      America has been a great nation since its star...  \n",
      "3      Later this month, students will be able to pay...  \n",
      "4      Attacks have been waged on single mothers. The...  \n",
      "...                                                  ...  \n",
      "13335  The university is offering a free course on me...  \n",
      "13336  Bo Durkac (right) worked closely with former B...  \n",
      "13337  The tournament will be played at the Amelia Ar...  \n",
      "13338  There should be an age limit for presidential ...  \n",
      "13339  Sophomore utility player Bobby Boser led the t...  \n",
      "\n",
      "[13340 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# The output DataFrame\n",
    "output_df = pd.DataFrame(columns=[\"date\", \"school\", \"keyword\", \"article\"])\n",
    "\n",
    "# Iterate through the keywords\n",
    "for keyword in keywords:\n",
    "    # Read the corresponding CSV file\n",
    "    df = pd.read_csv(f\"{grouped_data_path}/{SCHOOL}_{keyword}.csv\")\n",
    "\n",
    "    # Iterate through the dates in the DataFrame\n",
    "    for date in df[\"date\"]:\n",
    "        # Format the date in the correct format for the .txt file name\n",
    "        date_formatted = date.replace(\"-\", \"_\")\n",
    "\n",
    "        # Check if the .txt file exists\n",
    "        txt_files = glob.glob(f\"{data_path}/{date_formatted}*.txt\")\n",
    "        if txt_files:\n",
    "            # Open the .txt file and read its content\n",
    "            with open(txt_files[0], \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            if(SCHOOL == \"McGill\"):\n",
    "                # Split the content by the separator \"The McGill Daily\" repeated twice\n",
    "                articles = content.split(\"The McGill Daily\\nThe McGill Daily\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Radio\\nDownload file.*Powered by WordPress\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"Georgetown\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\"\n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Comment.*Creative\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"York\"):\n",
    "                # Split the content by the separator \"York University Community Newspaper\"\n",
    "                articles = content.split(\"York University Community Newspaper\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"\\s*York University Community Newspaper\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"CMU\"):\n",
    "                # Split the content by the separator \"Carnegie Mellon's Student Newspaper Since 1906.\"\n",
    "                articles = content.split(\"Carnegie Mellon's Student Newspaper Since 1906.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Archives.*Contact Us\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        cleaned_article = re.sub(\"\\n\\n  .*The Tartan\", \"\", cleaned_article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"USC\"):\n",
    "            # Split the content by the separator \"Extra en Español\"\n",
    "                articles = content.split(\"Extra en Español\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"This site .* allow them:\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            elif(SCHOOL == \"AU\"):\n",
    "                # Split the content by the separator \"Would you like to support our work? Donate here to The Eagle Innovation Fund.\"\n",
    "                articles = content.split(\"Would you like to support our work? Donate here to The Eagle Innovation Fund.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(© .*State News\\.)|(You can .*eagleonline\\.com\\.)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"LIU\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\" \n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(Your.* LIU Post)|(Official Newspaper of LIU Post)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "                new_row = pd.DataFrame({\n",
    "                    \"date\": [date],\n",
    "                    \"school\": [SCHOOL],\n",
    "                    \"keyword\": [keyword],\n",
    "                    \"article\": [content.strip()]  # Remove leading/trailing white spaces\n",
    "                })\n",
    "                output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "# Add a line space between each article\n",
    "output_df[\"article\"] = output_df[\"article\"] + \"\\n\"\n",
    "\n",
    "# Save the output DataFrame into a CSV file\n",
    "output_df.to_csv(output_path, index=False)\n",
    "print(output_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
