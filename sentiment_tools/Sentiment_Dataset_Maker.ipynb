{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change school, supported schools are: McGill, Georgetown, York, CMU, USC, AU, LIU\n",
    "SCHOOL = \"LIU\"\n",
    "keywords = []\n",
    "\n",
    "p = [\"conservative\", \"liberal\", \"Democrat\", \"Republican\", \"club\"]\n",
    "c = [\"China\", \"India\", \"Israel\", \"Palestine\"]\n",
    "n = [\"report\", \"research\", \"data\", \"analysis\", \"document\", \"study\", \"information\", \"observation\"]\n",
    "\n",
    "# Supports country, poli, neutral\n",
    "\n",
    "keyword_set = \"country\"\n",
    "\n",
    "if keyword_set == \"poli\":\n",
    "    keywords = p\n",
    "elif keyword_set == \"country\":\n",
    "    keywords = c\n",
    "else:\n",
    "    keywords = n\n",
    "\n",
    "data_path = f\"../journal_data/txt/{SCHOOL}\"\n",
    "output_path = f\"../bias_processing/data/1/{SCHOOL.lower()}_dataset_{keyword_set}.csv\"\n",
    "grouped_data_path = \"../grouped_data/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date school    keyword  \\\n",
      "0   2011-10-19    LIU      China   \n",
      "1   2011-10-26    LIU      China   \n",
      "2   2011-11-30    LIU      China   \n",
      "3   2011-12-14    LIU      China   \n",
      "4   2012-10-10    LIU      China   \n",
      "5   2012-10-17    LIU      China   \n",
      "6   2012-11-28    LIU      China   \n",
      "7   2013-11-20    LIU      China   \n",
      "8   2014-10-28    LIU      China   \n",
      "9   2015-10-27    LIU      China   \n",
      "10  2016-10-19    LIU      China   \n",
      "11  2017-10-10    LIU      China   \n",
      "12  2017-11-28    LIU      China   \n",
      "13  2018-10-10    LIU      China   \n",
      "14  2018-11-14    LIU      China   \n",
      "15  2021-11-25    LIU      China   \n",
      "16  2022-12-21    LIU      China   \n",
      "17  2010-10-21    LIU      India   \n",
      "18  2010-11-19    LIU      India   \n",
      "19  2012-10-10    LIU      India   \n",
      "20  2012-10-17    LIU      India   \n",
      "21  2012-11-14    LIU      India   \n",
      "22  2014-10-15    LIU      India   \n",
      "23  2014-10-28    LIU      India   \n",
      "24  2016-10-25    LIU      India   \n",
      "25  2016-11-30    LIU      India   \n",
      "26  2017-10-31    LIU      India   \n",
      "27  2018-10-16    LIU      India   \n",
      "28  2020-10-16    LIU      India   \n",
      "29  2020-11-12    LIU      India   \n",
      "30  2021-12-16    LIU      India   \n",
      "31  2011-11-30    LIU     Israel   \n",
      "32  2012-10-17    LIU     Israel   \n",
      "33  2015-10-13    LIU     Israel   \n",
      "34  2015-10-27    LIU     Israel   \n",
      "35  2015-11-17    LIU     Israel   \n",
      "36  2016-11-30    LIU     Israel   \n",
      "37  2017-10-10    LIU     Israel   \n",
      "38  2017-10-24    LIU     Israel   \n",
      "39  2018-10-24    LIU     Israel   \n",
      "40  2018-10-31    LIU     Israel   \n",
      "41  2015-10-13    LIU  Palestine   \n",
      "\n",
      "                                              article  \n",
      "0   May 19, 2023\\n\\nSandra Elien\\nHave you ever co...  \n",
      "1   May 19, 2023\\n\\nChantell Moore\\nC.W. Post stud...  \n",
      "2   May 19, 2023\\n\\nDecember 1st\\nGeneral Educatio...  \n",
      "3   May 19, 2023\\n\\nDecember 14th\\nWCWP General Me...  \n",
      "4   May 18, 2023\\n\\n\\nCristina Foglietta\\nStaff Wr...  \n",
      "5   May 18, 2023\\n\\n\\nErin Mei\\nStaff Writer\\nLIU ...  \n",
      "6   May 18, 2023\\n\\n\\nAmanda Bernocco\\nStaff Write...  \n",
      "7   May 18, 2023\\n\\nBy Alex Billington\\nStaff writ...  \n",
      "8   May 18, 2023\\n\\nBy Caroline Nickolaus\\nStaff W...  \n",
      "9   May 18, 2023\\n\\nBy Margaret Pepe\\nAssistant Fe...  \n",
      "10  May 18, 2023\\n\\nBy Caroline Ryan and Alec Matu...  \n",
      "11  May 18, 2023\\n\\nBy Caroline Ryan\\nEditor-in-Ch...  \n",
      "12  May 18, 2023\\n\\nBy Mikey Domagala\\nStaff Write...  \n",
      "13  May 18, 2023\\n\\nLast updated on Jun 11, 2019 \\...  \n",
      "14  May 18, 2023\\n\\nBy Karis Fuller\\nArts & Entert...  \n",
      "15  May 18, 2023\\n\\nBy Dean Joannou, Staff Writer\\...  \n",
      "16  May 18, 2023\\n\\nBy Andrew Scarpaci, Sports Edi...  \n",
      "17  May 19, 2023\\n\\nLetter to the readers,\\nNot on...  \n",
      "18  May 19, 2023\\n\\nMLB\\nTexas Rangers closer Neft...  \n",
      "19  May 18, 2023\\n\\n\\nCristina Foglietta\\nStaff Wr...  \n",
      "20  May 18, 2023\\n\\n\\nErin Mei\\nStaff Writer\\nLIU ...  \n",
      "21  May 18, 2023\\n\\n\\nJazlyn Beltre\\nStaff Writer\\...  \n",
      "22  May 18, 2023\\n\\nBy Kristen Linsalata\\nAssistan...  \n",
      "23  May 18, 2023\\n\\nBy Caroline Nickolaus\\nStaff W...  \n",
      "24  May 18, 2023\\n\\nLast updated on Oct 26, 2016 \\...  \n",
      "25  May 18, 2023\\n\\nBy Joseph Iemma\\nStaff Writer\\...  \n",
      "26  May 18, 2023\\n\\nLast updated on Nov 2, 2017 \\n...  \n",
      "27  May 18, 2023\\n\\nBy Josie Rerecich\\nStaff Write...  \n",
      "28  May 18, 2023\\n\\nBy Zach Taber, Staff Writer\\nW...  \n",
      "29  May 18, 2023\\n\\nLast updated on Nov 16, 2020 \\...  \n",
      "30  May 18, 2023\\n\\nBy Shelley Dean, Co-Arts-and-E...  \n",
      "31  May 19, 2023\\n\\nDecember 1st\\nGeneral Educatio...  \n",
      "32  May 18, 2023\\n\\n\\nErin Mei\\nStaff Writer\\nLIU ...  \n",
      "33  May 18, 2023\\n\\nBy Margaret Pepe\\nAssistant Fe...  \n",
      "34  May 18, 2023\\n\\nBy Margaret Pepe\\nAssistant Fe...  \n",
      "35  May 18, 2023\\n\\nBy Joseph Iemma\\nStaff Writer\\...  \n",
      "36  May 18, 2023\\n\\nBy Joseph Iemma\\nStaff Writer\\...  \n",
      "37  May 18, 2023\\n\\nBy Caroline Ryan\\nEditor-in-Ch...  \n",
      "38  May 18, 2023\\n\\nLast updated on Oct 30, 2017 \\...  \n",
      "39  May 18, 2023\\n\\nBy Alex Espinosa\\nStaff Writer...  \n",
      "40          May 18, 2023\\n\\n    \\nPublished in News\\n  \n",
      "41  May 18, 2023\\n\\nBy Margaret Pepe\\nAssistant Fe...  \n"
     ]
    }
   ],
   "source": [
    "# The output DataFrame\n",
    "output_df = pd.DataFrame(columns=[\"date\", \"school\", \"keyword\", \"article\"])\n",
    "\n",
    "# Iterate through the keywords\n",
    "for keyword in keywords:\n",
    "    # Read the corresponding CSV file\n",
    "    df = pd.read_csv(f\"{grouped_data_path}/{SCHOOL}_{keyword}.csv\")\n",
    "\n",
    "    # Iterate through the dates in the DataFrame\n",
    "    for date in df[\"date\"]:\n",
    "        # Format the date in the correct format for the .txt file name\n",
    "        date_formatted = date.replace(\"-\", \"_\")\n",
    "\n",
    "        # Check if the .txt file exists\n",
    "        txt_files = glob.glob(f\"{data_path}/{date_formatted}*.txt\")\n",
    "        if txt_files:\n",
    "            # Open the .txt file and read its content\n",
    "            with open(txt_files[0], \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            if(SCHOOL == \"McGill\"):\n",
    "                # Split the content by the separator \"The McGill Daily\" repeated twice\n",
    "                articles = content.split(\"The McGill Daily\\nThe McGill Daily\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Radio\\nDownload file.*Powered by WordPress\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"Georgetown\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\"\n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Comment.*Creative\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"York\"):\n",
    "                # Split the content by the separator \"York University Community Newspaper\"\n",
    "                articles = content.split(\"York University Community Newspaper\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"\\s*York University Community Newspaper\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"CMU\"):\n",
    "                # Split the content by the separator \"Carnegie Mellon's Student Newspaper Since 1906.\"\n",
    "                articles = content.split(\"Carnegie Mellon's Student Newspaper Since 1906.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Archives.*Contact Us\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        cleaned_article = re.sub(\"\\n\\n  .*The Tartan\", \"\", cleaned_article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"USC\"):\n",
    "            # Split the content by the separator \"Extra en Español\"\n",
    "                articles = content.split(\"Extra en Español\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"This site .* allow them:\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            elif(SCHOOL == \"AU\"):\n",
    "                # Split the content by the separator \"Would you like to support our work? Donate here to The Eagle Innovation Fund.\"\n",
    "                articles = content.split(\"Would you like to support our work? Donate here to The Eagle Innovation Fund.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(© .*State News\\.)|(You can .*eagleonline\\.com\\.)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"LIU\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\" \n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(Your.* LIU Post)|(Official Newspaper of LIU Post)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "                new_row = pd.DataFrame({\n",
    "                    \"date\": [date],\n",
    "                    \"school\": [SCHOOL],\n",
    "                    \"keyword\": [keyword],\n",
    "                    \"article\": [content.strip()]  # Remove leading/trailing white spaces\n",
    "                })\n",
    "                output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "# Add a line space between each article\n",
    "output_df[\"article\"] = output_df[\"article\"] + \"\\n\"\n",
    "\n",
    "# Save the output DataFrame into a CSV file\n",
    "output_df.to_csv(output_path, index=False)\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stacy\\Desktop\\Olami Project\\Olami\\sentiment_tools\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
