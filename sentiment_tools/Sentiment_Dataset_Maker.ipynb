{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change school, supported schools are: McGill, Georgetown, York, CMU, USC, AU, LIU\n",
    "SCHOOL = \"AU\"\n",
    "keywords = [\"China\", \"India\", \"Israel\", \"Palestine\"]\n",
    "data_path = f\"journal_data/txt/{SCHOOL}\"\n",
    "output_path = f\"bias_processing/data/1/{SCHOOL.lower()}_dataset.csv\"\n",
    "grouped_data_path = \"grouped_data/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date school    keyword  \\\n",
      "0    2009-02-12     AU      China   \n",
      "1    2009-08-13     AU      China   \n",
      "2    2009-08-13     AU      China   \n",
      "3    2009-08-13     AU      China   \n",
      "4    2009-08-13     AU      China   \n",
      "..          ...    ...        ...   \n",
      "121  2014-12-11     AU  Palestine   \n",
      "122  2015-11-12     AU  Palestine   \n",
      "123  2020-11-13     AU  Palestine   \n",
      "124  2022-02-11     AU  Palestine   \n",
      "125  2022-11-10     AU  Palestine   \n",
      "\n",
      "                                               article  \n",
      "0    A firefighter died after a 40-story Beijing lu...  \n",
      "1    To think of D.C. is to think of following drea...  \n",
      "2    Although swiping your card at TDR and sitting ...  \n",
      "3    For newcomers to AU and to D.C., this list is ...  \n",
      "4    There are only so many times that you can visi...  \n",
      "..                                                 ...  \n",
      "121  AU terminated its contract with the apparel co...  \n",
      "122  *Updated: 5:09 p.m. Nov. 14. Corrections and c...  \n",
      "123  Palestinian social justice event flyer. \\nAn A...  \n",
      "124  Tzipi Livni, the former Vice Premier, Minister...  \n",
      "125  Palestinian writer and spoken word poet Ghadee...  \n",
      "\n",
      "[126 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# The output DataFrame\n",
    "output_df = pd.DataFrame(columns=[\"date\", \"school\", \"keyword\", \"article\"])\n",
    "\n",
    "# Iterate through the keywords\n",
    "for keyword in keywords:\n",
    "    # Read the corresponding CSV file\n",
    "    df = pd.read_csv(f\"{grouped_data_path}/{SCHOOL}_{keyword}.csv\")\n",
    "\n",
    "    # Iterate through the dates in the DataFrame\n",
    "    for date in df[\"date\"]:\n",
    "        # Format the date in the correct format for the .txt file name\n",
    "        date_formatted = date.replace(\"-\", \"_\")\n",
    "\n",
    "        # Check if the .txt file exists\n",
    "        txt_files = glob.glob(f\"{data_path}/{date_formatted}*.txt\")\n",
    "        if txt_files:\n",
    "            # Open the .txt file and read its content\n",
    "            with open(txt_files[0], \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            if(SCHOOL == \"McGill\"):\n",
    "                # Split the content by the separator \"The McGill Daily\" repeated twice\n",
    "                articles = content.split(\"The McGill Daily\\nThe McGill Daily\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Radio\\nDownload file.*Powered by WordPress\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"Georgetown\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\"\n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Comment.*Creative\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"York\"):\n",
    "                # Split the content by the separator \"York University Community Newspaper\"\n",
    "                articles = content.split(\"York University Community Newspaper\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"\\s*York University Community Newspaper\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"CMU\"):\n",
    "                # Split the content by the separator \"Carnegie Mellon's Student Newspaper Since 1906.\"\n",
    "                articles = content.split(\"Carnegie Mellon's Student Newspaper Since 1906.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"Archives.*Contact Us\\n\\n\\n\", \"\", article, flags=re.DOTALL)\n",
    "                        cleaned_article = re.sub(\"\\n\\n  .*The Tartan\", \"\", cleaned_article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"USC\"):\n",
    "            # Split the content by the separator \"Extra en Español\"\n",
    "                articles = content.split(\"Extra en Español\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"This site .* allow them:\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            elif(SCHOOL == \"AU\"):\n",
    "                # Split the content by the separator \"Would you like to support our work? Donate here to The Eagle Innovation Fund.\"\n",
    "                articles = content.split(\"Would you like to support our work? Donate here to The Eagle Innovation Fund.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(© .*State News\\.)|(You can .*eagleonline\\.com\\.)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "            elif(SCHOOL == \"LIU\"):\n",
    "                # Split the content by the separator \"Your email address will not be published. Required fields are marked *\" \n",
    "                articles = content.split(\"Your email address will not be published. Required fields are marked *.\\n\")\n",
    "\n",
    "                # Iterate through the articles and check if the keyword is in the article\n",
    "                for article in articles:\n",
    "                    if keyword.lower() in article.lower():\n",
    "                        # If the keyword is in the article, remove footer and create a new DataFrame and append it to the output DataFrame\n",
    "                        cleaned_article = re.sub(\"(Your.* LIU Post)|(Official Newspaper of LIU Post)\", \"\", article, flags=re.DOTALL)\n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"date\": [date],\n",
    "                            \"school\": [SCHOOL],\n",
    "                            \"keyword\": [keyword],\n",
    "                            \"article\": [cleaned_article.strip()]  # Remove leading/trailing white spaces\n",
    "                        })\n",
    "                        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "                new_row = pd.DataFrame({\n",
    "                    \"date\": [date],\n",
    "                    \"school\": [SCHOOL],\n",
    "                    \"keyword\": [keyword],\n",
    "                    \"article\": [content.strip()]  # Remove leading/trailing white spaces\n",
    "                })\n",
    "                output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "\n",
    "# Add a line space between each article\n",
    "output_df[\"article\"] = output_df[\"article\"] + \"\\n\"\n",
    "\n",
    "# Save the output DataFrame into a CSV file\n",
    "output_df.to_csv(output_path, index=False)\n",
    "print(output_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
