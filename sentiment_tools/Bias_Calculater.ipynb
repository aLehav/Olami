{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHOOL = \"AU\"\n",
    "method = \"mean_diff\"\n",
    "sentiment_type = \"granularity\"\n",
    "sentiment_path_portion = \"3\" if sentiment_type == \"summarizer\" else \"2/nltk_sia\"\n",
    "data_path = f\"../bias_processing/data/{sentiment_path_portion}/{SCHOOL.lower()}_dataset_{sentiment_type}.poli.csv\"\n",
    "output_path = f\"../bias_processing/data/4/{SCHOOL.lower()}_bias_{method}.poli.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def score_computer_generator(method=method):\n",
    "    def score_computer(article_sentiment_scores, sentence_sentiment_scores):\n",
    "        if method == \"mean_avg\":\n",
    "            article_val = mean(article_sentiment_scores)\n",
    "            sentence_val = mean(sentence_sentiment_scores)\n",
    "            return (article_val + sentence_val) / 2\n",
    "        elif method == \"mean_diff\":\n",
    "            article_val = mean(article_sentiment_scores)\n",
    "            sentence_val = mean(sentence_sentiment_scores)\n",
    "            return article_val - sentence_val\n",
    "        elif method == \"diff_avg\":\n",
    "            differences = [a - b for a, b in zip(article_sentiment_scores, sentence_sentiment_scores)]\n",
    "            return mean(differences)\n",
    "        else:\n",
    "            raise(ValueError(\"Put in a valid method\"))\n",
    "    return score_computer\n",
    "scorer = score_computer_generator(method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGiven a csv from one of the Sentiment_Calculator notebooks, calculate bias by doing the following:\\nGroup by topic, and consider that 1 series\\nCompute variance between series of sentiment for entire article granularity and sentence-granularity for each of the labels (Positive, Negative, Neutral) leaving you with 3 values\\nAverage these values (add functionality to take max as well) and assume this to be 'bias'\\nStore the bias for a given school as a csv with the columns of School_Name, Israel_Bias, Palestine_Bias, India_Bias, China_Bias\\nSave a new csv with this entry, or load in a csv of past schools with these columns and add this row to the bottom\\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given a csv from one of the Sentiment_Calculator notebooks, calculate bias by doing the following:\n",
    "Group by topic, and consider that 1 series\n",
    "Compute variance between series of sentiment for entire article granularity and sentence-granularity for each of the labels (Positive, Negative, Neutral) leaving you with 3 values\n",
    "Average these values (add functionality to take max as well) and assume this to be 'bias'\n",
    "Store the bias for a given school as a csv with the columns of School_Name, Israel_Bias, Palestine_Bias, India_Bias, China_Bias\n",
    "Save a new csv with this entry, or load in a csv of past schools with these columns and add this row to the bottom\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         article_sentiment_scores \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mkeyword\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m keyword, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39marticle_\u001b[39m\u001b[39m{\u001b[39;00msentiment\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m         sentence_sentiment_scores \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mkeyword\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m keyword, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msentence_\u001b[39m\u001b[39m{\u001b[39;00msentiment\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m         result_dict[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkeyword\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00msentiment\u001b[39m}\u001b[39;00m\u001b[39m_Bias\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scorer(article_sentiment_scores, sentence_sentiment_scores)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Add the school name to the results dictionary\u001b[39;00m\n\u001b[1;32m     28\u001b[0m result_dict[\u001b[39m'\u001b[39m\u001b[39mSchool_Name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m SCHOOL\n",
      "Cell \u001b[0;32mIn[106], line 10\u001b[0m, in \u001b[0;36mscore_computer_generator.<locals>.score_computer\u001b[0;34m(article_sentiment_scores, sentence_sentiment_scores)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m (article_val \u001b[39m+\u001b[39m sentence_val) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean_diff\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     article_val \u001b[39m=\u001b[39m mean(article_sentiment_scores)\n\u001b[1;32m     11\u001b[0m     sentence_val \u001b[39m=\u001b[39m mean(sentence_sentiment_scores)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m article_val \u001b[39m-\u001b[39m sentence_val\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/statistics.py:315\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    313\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m StatisticsError(\u001b[39m'\u001b[39m\u001b[39mmean requires at least one data point\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    316\u001b[0m T, total, count \u001b[39m=\u001b[39m _sum(data)\n\u001b[1;32m    317\u001b[0m \u001b[39massert\u001b[39;00m count \u001b[39m==\u001b[39m n\n",
      "\u001b[0;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this version, the bias is calculated as the average of the variances of the sentiment scores \n",
    "within each granularity (article and sentence).\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define the keywords and sentiments to be processed\n",
    "keywords = ['Democrat', 'Repulican', 'conservative', 'liberal', 'club']\n",
    "sentiments = ['pos', 'neg', 'neu']\n",
    "\n",
    "# Initialize a dictionary to store the bias for each keyword and sentiment\n",
    "result_dict = {f'{keyword}_{sentiment}_Bias': [] for keyword in keywords for sentiment in sentiments}\n",
    "\n",
    "# Loop over each keyword and sentiment\n",
    "for keyword in keywords:\n",
    "    for sentiment in sentiments:\n",
    "        # Extract the sentiment scores for the keyword from the dataframe\n",
    "        article_sentiment_scores = df.loc[df['keyword'] == keyword, f'article_{sentiment}']\n",
    "        sentence_sentiment_scores = df.loc[df['keyword'] == keyword, f'sentence_{sentiment}']\n",
    "\n",
    "        result_dict[f'{keyword}_{sentiment}_Bias'] = scorer(article_sentiment_scores, sentence_sentiment_scores)\n",
    "\n",
    "# Add the school name to the results dictionary\n",
    "result_dict['School_Name'] = SCHOOL\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "result_df = pd.DataFrame(result_dict, index=[0])\n",
    "\n",
    "# If the output file already exists, load the existing data and append the new data only if it's not duplicate\n",
    "if os.path.exists(output_path):\n",
    "    existing_df = pd.read_csv(output_path)\n",
    "    if not existing_df.equals(result_df):\n",
    "        result_df.to_csv(output_path, mode='a', header=False, index=False)\n",
    "# If it doesn't exist, create a new file\n",
    "else:\n",
    "    result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# In this version, the bias is calculated as the average of the variance of the differences between \n",
    "# the sentiment scores for article and sentence granularities.\n",
    "# \"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the name of the school and the file paths\n",
    "# SCHOOL = \"McGill\"\n",
    "# data_path = f\"bias_processing/data/2/nltk_sia/{SCHOOL.lower()}_dataset_granularity.csv\"\n",
    "# output_path = f\"bias_processing/data/4/{SCHOOL.lower()}_bias_granularity_v1.csv\"\n",
    "\n",
    "# # Read the data from the CSV file\n",
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# # Define the keywords and sentiments to be processed\n",
    "# keywords = ['Israel', 'Palestine', 'India', 'China']\n",
    "# sentiments = ['pos', 'neg', 'neu']\n",
    "\n",
    "# # Initialize a dictionary to store the average variance for each keyword and sentiment\n",
    "# result_dict = {}\n",
    "\n",
    "# # Loop over each keyword\n",
    "# for keyword in keywords:\n",
    "#     # Filter the dataframe by the keyword\n",
    "#     keyword_df = df[df['keyword'] == keyword]\n",
    "#     # Loop over each sentiment\n",
    "#     for sentiment in sentiments:\n",
    "#         # Initialize a list to store the variance for each granularity\n",
    "#         variances = []\n",
    "#         # Loop over each granularity\n",
    "#         for granularity in ['article', 'paragraph', 'sentence']:\n",
    "#             # Calculate the variance of the sentiment scores for the granularity and append it to the list\n",
    "#             variances.append(keyword_df[f'{granularity}_{sentiment}'].var())\n",
    "#         # Calculate the mean of the variances and store it in the results dictionary\n",
    "#         result_dict[f'{keyword}_Bias_{sentiment}'] = np.mean(variances)\n",
    "\n",
    "# # Convert the results dictionary to a DataFrame\n",
    "# result_df = pd.DataFrame.from_dict(result_dict, orient='index', columns=['Average Variance'])\n",
    "\n",
    "# # Transpose the DataFrame to match the desired output\n",
    "# result_df = result_df.transpose()\n",
    "\n",
    "# # Add the school name to the DataFrame\n",
    "# result_df['School_Name'] = SCHOOL\n",
    "\n",
    "# # Write the DataFrame to the CSV file\n",
    "# result_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# In this version, the bias is calculated as the average of the variances of the sentiment scores \n",
    "# within each granularity (Full Article, Article Summary, and Paragraph Summary).\n",
    "# \"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the name of the school for which the data will be processed\n",
    "# SCHOOL = \"McGill\"\n",
    "\n",
    "# # Define the file paths for the input and output CSV files\n",
    "# data_path = f\"bias_processing/data/3/{SCHOOL.lower()}_dataset_summarizer.csv\"\n",
    "# output_path = f\"bias_processing/data/4/{SCHOOL.lower()}_bias.summarizer_v1.csv\"\n",
    "\n",
    "# # Load the data from the CSV file\n",
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# # Calculate the variance of 'Full Article', 'Article Summary', and 'Paragraph Summary' \n",
    "# # for each 'Type' and 'School' across all dates. Reset the index so that \n",
    "# # 'School' and 'Type' become columns instead of indices.\n",
    "# df_var = df.groupby(['School', 'Type']).agg(\n",
    "#     full_article_var=pd.NamedAgg(column='Full Article', aggfunc=np.var),\n",
    "#     article_summary_var=pd.NamedAgg(column='Article Summary', aggfunc=np.var),\n",
    "#     paragraph_summary_var=pd.NamedAgg(column='Paragraph Summary', aggfunc=np.var)\n",
    "# ).reset_index()\n",
    "\n",
    "# # Reshape the df_var DataFrame to long format, turning 'Type' into columns and \n",
    "# # their variance as the 'Variance' values\n",
    "# df_pivot = df_var.melt(id_vars=['School', 'Type'], var_name='Granularity', value_name='Variance')\n",
    "\n",
    "# # Group the reshaped DataFrame by 'School', 'Type' and 'Granularity', then calculate \n",
    "# # the mean of 'Variance' for each group. This gives the average variance (bias) for \n",
    "# # each sentiment type for the specified school. Reset the index so that \n",
    "# # 'School', 'Type' and 'Granularity' become columns instead of indices.\n",
    "# df_avg = df_pivot.groupby(['School', 'Type', 'Granularity']).agg({'Variance': 'mean'}).reset_index()\n",
    "\n",
    "# # Rename the columns to reflect their corresponding bias and replace the 'School' \n",
    "# # column name with 'School_Name'\n",
    "# df_avg.columns = [f'{i}_Bias' if i != 'School' else i for i in df_avg.columns]\n",
    "# df_avg = df_avg.rename(columns={'School': 'School_Name'}).replace({'School_Name': {SCHOOL: SCHOOL}})\n",
    "\n",
    "# # Save the resulting DataFrame with the average variance (bias) as a new CSV file\n",
    "# df_avg.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# output_path = f\"bias_processing/data/4/{SCHOOL.lower()}_bias.summarizer_v2.csv\"\n",
    "\n",
    "# # Reshape the DataFrame to long format, turning the granularity columns into \n",
    "# # individual rows and their values as the 'Score'\n",
    "# df_melt = df.melt(id_vars=['Date', 'School', 'Keyword', 'Type'], \n",
    "#                   var_name='Granularity', \n",
    "#                   value_name='Score')\n",
    "\n",
    "# # Group the reshaped DataFrame by 'School', 'Type' and 'Granularity', then calculate \n",
    "# # the variance ('np.var') of 'Score' for each group. Reset the index so that \n",
    "# # 'School', 'Type' and 'Granularity' become columns instead of indices.\n",
    "# df_var = df_melt.groupby(['School', 'Type', 'Granularity'])\\\n",
    "#                 .agg({'Score': np.var})\\\n",
    "#                 .reset_index()\n",
    "\n",
    "# # Group the variance DataFrame by 'Granularity', calculate the mean of the 'Score' \n",
    "# # for each group (which will give us the average variance for each granularity), \n",
    "# # and reset the index.\n",
    "# df_avg_var = df_var.groupby('Granularity')\\\n",
    "#                    .agg({'Score': 'mean'})\\\n",
    "#                    .reset_index()\n",
    "\n",
    "# # Rename the columns of the average variance DataFrame to more accurately \n",
    "# # reflect what they represent: 'Granularity' and 'Average_Variance'\n",
    "# df_avg_var.columns = ['Granularity', 'Average_Variance']\n",
    "\n",
    "# # Print the final DataFrame, which shows the average variance for each granularity\n",
    "# print(df_avg_var)\n",
    "\n",
    "# df_avg_var.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
